---
title: 为什么提示注入理应无解
date: 2025-07-04 17:54:03
tags:
---

先说我的结论：提示词注入，不是 bug，是 feature。

如果你真以为能有一种万能的办法控制所谓“注入”的问题，那你最终能做的，也不过是对上下文窗口进行审查。就像广电总局那样，把被认为有害的内容隔离出来。

为什么呢？

因为“注入”的提示词本来就是上下文的一部分，文字 A 和文字 B 之间并没有本质区别。当它们组合成 AB 时，除了做输入过滤，你别无选择。当然，你也可以通过训练让模型学会“自我审查”，这当然是可以的。但说实话，这让我感到一种深深的悲哀。

作为人类，当你读到“明月松间照，清泉石上流”，脑海中浮现的是空谷幽林、清风明月；当你听维瓦尔第的《四季·冬》，会想起《燃烧女子的画像》中那种暧昧而克制的情愫。即使在礼教之下，那种情感依然燃烧不息。

或者当我们交谈时，随口提到一个四字成语，“愚公移山”，又或者随便提一个网络梗，大量信息就这样瞬间来到了我们的语境之中。

这些是提示词注入吗？是的。

而这正是语言的魅力。你要是禁锢语言的上下文窗口，就是在阉割思维。

我说这是“无解”，并不是说技术上完全无计可施。你当然可以用正则表达式清除那些所谓有害的信息，或者训练一个小模型监控输入内容。

但是，为什么我们还要这么做呢？我们倾尽所能，拿人世间所有的文字，去训练出的大模型，在很多人眼中依旧是个“不成熟的孩子”。就好像父母眼里永远长不大的孩子。也许大模型也永远会是一个孩子，就像全人类一样。

人类的大脑，虽然在出生时结构已经具备，但真正让它生出沟壑的，是后天的训练。所以微调才那么重要。它决定了模型在接收到某些“危险提示”时，是否具备判断力。虽然“判断”这个词听起来太主观了。

我们太急于让模型像人，却从未认真反省过，人究竟是什么。

我们希望大模型懂伦理，守规矩，却忘了人类自己尚且在灰暗中挣扎。
